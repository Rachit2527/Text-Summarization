{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrtXet7br-EM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\"Text summarization is commonly used by several websites and applications to create news feed and article summaries. It has become very essential for us due to our busy schedules. We prefer short summaries with all the important points over reading a whole report and summarizing it ourselves. So, several attempts had been made to automate the summarizing process. In this article, we will talk about some of them and see how they work.\n",
        "\n",
        "What is summarization?\n",
        "Summarization is a technique to shorten long texts such that the summary has all the important points of the actual document.\n",
        "\n",
        "There are mainly four types of summaries:\n",
        "\n",
        "Single Document Summary: Summary of a Single Document\n",
        "Multi-Document Summary: Summary from multiple documents\n",
        "Query Focused Summary: Summary of a specific query\n",
        "Informative Summary: It includes a summary of the full information.\n",
        "Approaches to Automatic summarization\n",
        "There are mainly two types of summarization:\n",
        "\n",
        "Extraction-based Summarization: The extractive approach involves picking up the most important phrases and lines from the documents. It then combines all the important lines to create the summary. So, in this case, every line and word of the summary actually belongs to the original document which is summarized.\n",
        "\n",
        "Abstraction-based Summarization: The abstractive approach involves summarization based on deep learning. So, it uses new phrases and terms, different from the actual document, keeping the points the same, just like how we actually summarize. So, it is much harder than the extractive approach.\n",
        "\n",
        "It has been observed that extractive summaries sometimes work better than the abstractive ones probably because extractive ones don’t require natural language generations and semantic representations.\n",
        "\n",
        "Evaluation methods\n",
        "There are two types of evaluations:\n",
        "\n",
        "Human Evaluation\n",
        "Automatic Evaluation\"\"\""
      ],
      "metadata": {
        "id": "xBNBUNfZsFvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDh-jE5psI-S",
        "outputId": "051490bf-6cc7-45b1-daba-f7331ed564a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "y4dTiGYtsMEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation"
      ],
      "metadata": {
        "id": "zMc4hlXlsPJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = list(STOP_WORDS)\n",
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zRDz8BGsSCR",
        "outputId": "f9a5323f-e02f-42e5-d22b-7c76fbbda5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['seem',\n",
              " 'between',\n",
              " 'via',\n",
              " 'hereafter',\n",
              " 'whenever',\n",
              " 'am',\n",
              " 'nowhere',\n",
              " 'yourself',\n",
              " 'who',\n",
              " 'we',\n",
              " 'his',\n",
              " 'across',\n",
              " 'next',\n",
              " 'why',\n",
              " 'by',\n",
              " 'had',\n",
              " 'never',\n",
              " 'toward',\n",
              " 'always',\n",
              " 'done',\n",
              " 'make',\n",
              " 'n‘t',\n",
              " 'regarding',\n",
              " 'therein',\n",
              " 'call',\n",
              " 'bottom',\n",
              " 'anywhere',\n",
              " 'various',\n",
              " 'six',\n",
              " 'both',\n",
              " 'this',\n",
              " 'thereafter',\n",
              " 'amongst',\n",
              " 'per',\n",
              " 'were',\n",
              " 'before',\n",
              " 'whereas',\n",
              " 'made',\n",
              " '‘d',\n",
              " 'whole',\n",
              " '’ve',\n",
              " 'now',\n",
              " 'than',\n",
              " 'give',\n",
              " 'their',\n",
              " 'nevertheless',\n",
              " 'because',\n",
              " 'hence',\n",
              " 'do',\n",
              " 'other',\n",
              " 'everywhere',\n",
              " 'mine',\n",
              " 'please',\n",
              " \"'ve\",\n",
              " 'each',\n",
              " 'sometimes',\n",
              " 'an',\n",
              " '‘re',\n",
              " 'mostly',\n",
              " 'only',\n",
              " 'thereby',\n",
              " 'all',\n",
              " 'any',\n",
              " 'along',\n",
              " 'even',\n",
              " 'top',\n",
              " 'how',\n",
              " 'already',\n",
              " 'i',\n",
              " 'one',\n",
              " \"'re\",\n",
              " 'most',\n",
              " 'been',\n",
              " 'two',\n",
              " 'twenty',\n",
              " 'everything',\n",
              " 'that',\n",
              " 'was',\n",
              " 'ours',\n",
              " 'hundred',\n",
              " 'has',\n",
              " 'something',\n",
              " 'within',\n",
              " 'further',\n",
              " 'five',\n",
              " 'when',\n",
              " 'due',\n",
              " 'whether',\n",
              " 'indeed',\n",
              " 'he',\n",
              " 'in',\n",
              " '‘ve',\n",
              " 'could',\n",
              " 'part',\n",
              " 'they',\n",
              " 'same',\n",
              " 'fifty',\n",
              " 'them',\n",
              " 'although',\n",
              " 'see',\n",
              " 'herself',\n",
              " 'down',\n",
              " 'third',\n",
              " 'much',\n",
              " 'either',\n",
              " 'elsewhere',\n",
              " 'used',\n",
              " 'some',\n",
              " 'becoming',\n",
              " 'take',\n",
              " 'get',\n",
              " 'enough',\n",
              " 'somehow',\n",
              " 'put',\n",
              " '‘m',\n",
              " 'must',\n",
              " 'these',\n",
              " '’re',\n",
              " 'side',\n",
              " 'my',\n",
              " 'themselves',\n",
              " 'should',\n",
              " 'with',\n",
              " 'neither',\n",
              " 'ca',\n",
              " 'too',\n",
              " 'if',\n",
              " 'thence',\n",
              " 'being',\n",
              " 'onto',\n",
              " 'beside',\n",
              " 'namely',\n",
              " 'over',\n",
              " 'to',\n",
              " 'her',\n",
              " 'otherwise',\n",
              " 'your',\n",
              " 'nor',\n",
              " 'doing',\n",
              " 'through',\n",
              " 'hereupon',\n",
              " 'former',\n",
              " 'thru',\n",
              " \"'m\",\n",
              " 'unless',\n",
              " 'whence',\n",
              " 'thus',\n",
              " 'nothing',\n",
              " 'whither',\n",
              " '’s',\n",
              " 'amount',\n",
              " 'besides',\n",
              " 'n’t',\n",
              " 'beyond',\n",
              " 'just',\n",
              " 'does',\n",
              " 'therefore',\n",
              " 'many',\n",
              " 'perhaps',\n",
              " 'back',\n",
              " 'others',\n",
              " 'full',\n",
              " 'everyone',\n",
              " 'three',\n",
              " 'upon',\n",
              " 'few',\n",
              " 'seemed',\n",
              " '’m',\n",
              " 'while',\n",
              " 'into',\n",
              " 'whatever',\n",
              " 'becomes',\n",
              " 'from',\n",
              " 'well',\n",
              " 'yours',\n",
              " 'under',\n",
              " 'of',\n",
              " 'afterwards',\n",
              " 'as',\n",
              " 'hereby',\n",
              " 'rather',\n",
              " 'after',\n",
              " '‘s',\n",
              " 'none',\n",
              " 'someone',\n",
              " 'ourselves',\n",
              " 'here',\n",
              " 'whereupon',\n",
              " 'whose',\n",
              " 'sixty',\n",
              " 'seeming',\n",
              " 'would',\n",
              " 'also',\n",
              " 'less',\n",
              " 'without',\n",
              " 'against',\n",
              " 'so',\n",
              " 'until',\n",
              " 'not',\n",
              " 'might',\n",
              " 'latter',\n",
              " 'among',\n",
              " 'will',\n",
              " '‘ll',\n",
              " 'himself',\n",
              " 'together',\n",
              " \"'d\",\n",
              " 'became',\n",
              " 'latterly',\n",
              " 'become',\n",
              " '’d',\n",
              " '’ll',\n",
              " 'yourselves',\n",
              " 'me',\n",
              " 'what',\n",
              " \"'s\",\n",
              " 'name',\n",
              " 'those',\n",
              " 'ten',\n",
              " 'alone',\n",
              " 'more',\n",
              " 'you',\n",
              " 'is',\n",
              " 'forty',\n",
              " 'every',\n",
              " 'again',\n",
              " 'it',\n",
              " 'very',\n",
              " 'or',\n",
              " 'then',\n",
              " 'nine',\n",
              " 'another',\n",
              " 'twelve',\n",
              " 'wherein',\n",
              " 'nobody',\n",
              " 'whom',\n",
              " 'once',\n",
              " 'eight',\n",
              " 'sometime',\n",
              " 'ever',\n",
              " 'but',\n",
              " 'noone',\n",
              " 'whereafter',\n",
              " 'off',\n",
              " 'about',\n",
              " 'front',\n",
              " 'own',\n",
              " 'several',\n",
              " 'thereupon',\n",
              " 'anyhow',\n",
              " \"n't\",\n",
              " 'eleven',\n",
              " 'such',\n",
              " 'anyway',\n",
              " 'around',\n",
              " 'and',\n",
              " 'whereby',\n",
              " 'him',\n",
              " 'four',\n",
              " 'serious',\n",
              " 'cannot',\n",
              " 'go',\n",
              " 'herein',\n",
              " 'first',\n",
              " 'moreover',\n",
              " 'anyone',\n",
              " 'our',\n",
              " 'are',\n",
              " 'can',\n",
              " 'move',\n",
              " 'for',\n",
              " 'often',\n",
              " 'meanwhile',\n",
              " 'using',\n",
              " 'up',\n",
              " 'formerly',\n",
              " 'seems',\n",
              " 'almost',\n",
              " 'whoever',\n",
              " 'did',\n",
              " 'fifteen',\n",
              " 'except',\n",
              " 'show',\n",
              " 'a',\n",
              " 'where',\n",
              " 'since',\n",
              " 'yet',\n",
              " 'somewhere',\n",
              " 'beforehand',\n",
              " 'still',\n",
              " 'during',\n",
              " 'however',\n",
              " 'be',\n",
              " 'else',\n",
              " 'us',\n",
              " 'hers',\n",
              " 'wherever',\n",
              " 'quite',\n",
              " 'may',\n",
              " 'which',\n",
              " 'she',\n",
              " 'its',\n",
              " 'at',\n",
              " 'below',\n",
              " 'there',\n",
              " 'itself',\n",
              " 'the',\n",
              " 'though',\n",
              " 'no',\n",
              " \"'ll\",\n",
              " 'anything',\n",
              " 'behind',\n",
              " 'towards',\n",
              " 'throughout',\n",
              " 're',\n",
              " 'say',\n",
              " 'least',\n",
              " 'keep',\n",
              " 'empty',\n",
              " 'last',\n",
              " 'really',\n",
              " 'myself',\n",
              " 'above',\n",
              " 'on',\n",
              " 'out',\n",
              " 'have']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "qOvPfzPJsT60",
        "outputId": "77056cd1-011d-4a80-e761-9209ec9446b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "JuDD2mtKse_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm35ALYJsj3X",
        "outputId": "bebafa26-9451-4ad3-ef23-053c3dec8d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"', 'Text', 'summarization', 'is', 'commonly', 'used', 'by', 'several', 'websites', 'and', 'applications', 'to', 'create', 'news', 'feed', 'and', 'article', 'summaries', '.', 'It', 'has', 'become', 'very', 'essential', 'for', 'us', 'due', 'to', 'our', 'busy', 'schedules', '.', 'We', 'prefer', 'short', 'summaries', 'with', 'all', 'the', 'important', 'points', 'over', 'reading', 'a', 'whole', 'report', 'and', 'summarizing', 'it', 'ourselves', '.', 'So', ',', 'several', 'attempts', 'had', 'been', 'made', 'to', 'automate', 'the', 'summarizing', 'process', '.', 'In', 'this', 'article', ',', 'we', 'will', 'talk', 'about', 'some', 'of', 'them', 'and', 'see', 'how', 'they', 'work', '.', '\\n\\n', 'What', 'is', 'summarization', '?', '\\n', 'Summarization', 'is', 'a', 'technique', 'to', 'shorten', 'long', 'texts', 'such', 'that', 'the', 'summary', 'has', 'all', 'the', 'important', 'points', 'of', 'the', 'actual', 'document', '.', '\\n\\n', 'There', 'are', 'mainly', 'four', 'types', 'of', 'summaries', ':', '\\n\\n', 'Single', 'Document', 'Summary', ':', 'Summary', 'of', 'a', 'Single', 'Document', '\\n', 'Multi', '-', 'Document', 'Summary', ':', 'Summary', 'from', 'multiple', 'documents', '\\n', 'Query', 'Focused', 'Summary', ':', 'Summary', 'of', 'a', 'specific', 'query', '\\n', 'Informative', 'Summary', ':', 'It', 'includes', 'a', 'summary', 'of', 'the', 'full', 'information', '.', '\\n', 'Approaches', 'to', 'Automatic', 'summarization', '\\n', 'There', 'are', 'mainly', 'two', 'types', 'of', 'summarization', ':', '\\n\\n', 'Extraction', '-', 'based', 'Summarization', ':', 'The', 'extractive', 'approach', 'involves', 'picking', 'up', 'the', 'most', 'important', 'phrases', 'and', 'lines', 'from', 'the', 'documents', '.', 'It', 'then', 'combines', 'all', 'the', 'important', 'lines', 'to', 'create', 'the', 'summary', '.', 'So', ',', 'in', 'this', 'case', ',', 'every', 'line', 'and', 'word', 'of', 'the', 'summary', 'actually', 'belongs', 'to', 'the', 'original', 'document', 'which', 'is', 'summarized', '.', '\\n\\n', 'Abstraction', '-', 'based', 'Summarization', ':', 'The', 'abstractive', 'approach', 'involves', 'summarization', 'based', 'on', 'deep', 'learning', '.', 'So', ',', 'it', 'uses', 'new', 'phrases', 'and', 'terms', ',', 'different', 'from', 'the', 'actual', 'document', ',', 'keeping', 'the', 'points', 'the', 'same', ',', 'just', 'like', 'how', 'we', 'actually', 'summarize', '.', 'So', ',', 'it', 'is', 'much', 'harder', 'than', 'the', 'extractive', 'approach', '.', '\\n\\n', 'It', 'has', 'been', 'observed', 'that', 'extractive', 'summaries', 'sometimes', 'work', 'better', 'than', 'the', 'abstractive', 'ones', 'probably', 'because', 'extractive', 'ones', 'do', 'n’t', 'require', 'natural', 'language', 'generations', 'and', 'semantic', 'representations', '.', '\\n\\n', 'Evaluation', 'methods', '\\n', 'There', 'are', 'two', 'types', 'of', 'evaluations', ':', '\\n\\n', 'Human', 'Evaluation', '\\n', 'Automatic', 'Evaluation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = punctuation+'\\n'\n",
        "punctuation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08CCa_Bs329",
        "outputId": "31e99a0b-9ef8-4b10-fd31-e75cb08aaaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = {}\n",
        "\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stopwords:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text.lower() not in word_frequencies.keys():\n",
        "        word_frequencies[word.text.lower()] = 1\n",
        "      else:\n",
        "        word_frequencies[word.text.lower()] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "0NWdEuV4tBKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcTPMOQauuRD",
        "outputId": "fc598fe9-ac5f-46ac-f25d-bc8e253c6d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 1,\n",
              " 'summarization': 8,\n",
              " 'commonly': 1,\n",
              " 'websites': 1,\n",
              " 'applications': 1,\n",
              " 'create': 2,\n",
              " 'news': 1,\n",
              " 'feed': 1,\n",
              " 'article': 2,\n",
              " 'summaries': 4,\n",
              " 'essential': 1,\n",
              " 'busy': 1,\n",
              " 'schedules': 1,\n",
              " 'prefer': 1,\n",
              " 'short': 1,\n",
              " 'important': 4,\n",
              " 'points': 3,\n",
              " 'reading': 1,\n",
              " 'report': 1,\n",
              " 'summarizing': 2,\n",
              " 'attempts': 1,\n",
              " 'automate': 1,\n",
              " 'process': 1,\n",
              " 'talk': 1,\n",
              " 'work': 2,\n",
              " '\\n\\n': 8,\n",
              " 'technique': 1,\n",
              " 'shorten': 1,\n",
              " 'long': 1,\n",
              " 'texts': 1,\n",
              " 'summary': 11,\n",
              " 'actual': 2,\n",
              " 'document': 6,\n",
              " 'mainly': 2,\n",
              " 'types': 3,\n",
              " 'single': 2,\n",
              " 'multi': 1,\n",
              " 'multiple': 1,\n",
              " 'documents': 2,\n",
              " 'query': 2,\n",
              " 'focused': 1,\n",
              " 'specific': 1,\n",
              " 'informative': 1,\n",
              " 'includes': 1,\n",
              " 'information': 1,\n",
              " 'approaches': 1,\n",
              " 'automatic': 2,\n",
              " 'extraction': 1,\n",
              " 'based': 3,\n",
              " 'extractive': 4,\n",
              " 'approach': 3,\n",
              " 'involves': 2,\n",
              " 'picking': 1,\n",
              " 'phrases': 2,\n",
              " 'lines': 2,\n",
              " 'combines': 1,\n",
              " 'case': 1,\n",
              " 'line': 1,\n",
              " 'word': 1,\n",
              " 'actually': 2,\n",
              " 'belongs': 1,\n",
              " 'original': 1,\n",
              " 'summarized': 1,\n",
              " 'abstraction': 1,\n",
              " 'abstractive': 2,\n",
              " 'deep': 1,\n",
              " 'learning': 1,\n",
              " 'uses': 1,\n",
              " 'new': 1,\n",
              " 'terms': 1,\n",
              " 'different': 1,\n",
              " 'keeping': 1,\n",
              " 'like': 1,\n",
              " 'summarize': 1,\n",
              " 'harder': 1,\n",
              " 'observed': 1,\n",
              " 'better': 1,\n",
              " 'ones': 2,\n",
              " 'probably': 1,\n",
              " 'require': 1,\n",
              " 'natural': 1,\n",
              " 'language': 1,\n",
              " 'generations': 1,\n",
              " 'semantic': 1,\n",
              " 'representations': 1,\n",
              " 'evaluation': 3,\n",
              " 'methods': 1,\n",
              " 'evaluations': 1,\n",
              " 'human': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequencies.values())"
      ],
      "metadata": {
        "id": "0zht23IXvitt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZUrCszZvqMa",
        "outputId": "303c1892-0c70-4dd5-de9a-7250d64b3dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] =  word_frequencies[word]/max_frequency"
      ],
      "metadata": {
        "id": "TP-wmt3WvtzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLMvy2nyv_wR",
        "outputId": "a147f19e-0e8a-4889-df2f-44aa13feb7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 0.09090909090909091, 'summarization': 0.7272727272727273, 'commonly': 0.09090909090909091, 'websites': 0.09090909090909091, 'applications': 0.09090909090909091, 'create': 0.18181818181818182, 'news': 0.09090909090909091, 'feed': 0.09090909090909091, 'article': 0.18181818181818182, 'summaries': 0.36363636363636365, 'essential': 0.09090909090909091, 'busy': 0.09090909090909091, 'schedules': 0.09090909090909091, 'prefer': 0.09090909090909091, 'short': 0.09090909090909091, 'important': 0.36363636363636365, 'points': 0.2727272727272727, 'reading': 0.09090909090909091, 'report': 0.09090909090909091, 'summarizing': 0.18181818181818182, 'attempts': 0.09090909090909091, 'automate': 0.09090909090909091, 'process': 0.09090909090909091, 'talk': 0.09090909090909091, 'work': 0.18181818181818182, '\\n\\n': 0.7272727272727273, 'technique': 0.09090909090909091, 'shorten': 0.09090909090909091, 'long': 0.09090909090909091, 'texts': 0.09090909090909091, 'summary': 1.0, 'actual': 0.18181818181818182, 'document': 0.5454545454545454, 'mainly': 0.18181818181818182, 'types': 0.2727272727272727, 'single': 0.18181818181818182, 'multi': 0.09090909090909091, 'multiple': 0.09090909090909091, 'documents': 0.18181818181818182, 'query': 0.18181818181818182, 'focused': 0.09090909090909091, 'specific': 0.09090909090909091, 'informative': 0.09090909090909091, 'includes': 0.09090909090909091, 'information': 0.09090909090909091, 'approaches': 0.09090909090909091, 'automatic': 0.18181818181818182, 'extraction': 0.09090909090909091, 'based': 0.2727272727272727, 'extractive': 0.36363636363636365, 'approach': 0.2727272727272727, 'involves': 0.18181818181818182, 'picking': 0.09090909090909091, 'phrases': 0.18181818181818182, 'lines': 0.18181818181818182, 'combines': 0.09090909090909091, 'case': 0.09090909090909091, 'line': 0.09090909090909091, 'word': 0.09090909090909091, 'actually': 0.18181818181818182, 'belongs': 0.09090909090909091, 'original': 0.09090909090909091, 'summarized': 0.09090909090909091, 'abstraction': 0.09090909090909091, 'abstractive': 0.18181818181818182, 'deep': 0.09090909090909091, 'learning': 0.09090909090909091, 'uses': 0.09090909090909091, 'new': 0.09090909090909091, 'terms': 0.09090909090909091, 'different': 0.09090909090909091, 'keeping': 0.09090909090909091, 'like': 0.09090909090909091, 'summarize': 0.09090909090909091, 'harder': 0.09090909090909091, 'observed': 0.09090909090909091, 'better': 0.09090909090909091, 'ones': 0.18181818181818182, 'probably': 0.09090909090909091, 'require': 0.09090909090909091, 'natural': 0.09090909090909091, 'language': 0.09090909090909091, 'generations': 0.09090909090909091, 'semantic': 0.09090909090909091, 'representations': 0.09090909090909091, 'evaluation': 0.2727272727272727, 'methods': 0.09090909090909091, 'evaluations': 0.09090909090909091, 'human': 0.09090909090909091}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "print(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h420TL7TwKB_",
        "outputId": "47247731-5f3b-489a-9e8d-3066a69f9a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Text summarization is commonly used by several websites and applications to create news feed and article summaries., It has become very essential for us due to our busy schedules., We prefer short summaries with all the important points over reading a whole report and summarizing it ourselves., So, several attempts had been made to automate the summarizing process., In this article, we will talk about some of them and see how they work.\n",
            "\n",
            ", What is summarization?\n",
            "Summarization is a technique to shorten long texts such that the summary has all the important points of the actual document.\n",
            "\n",
            ", There are mainly four types of summaries:\n",
            "\n",
            "Single Document Summary: Summary of a Single Document\n",
            "Multi-Document Summary: Summary from multiple documents\n",
            "Query Focused Summary: Summary of a specific query\n",
            "Informative Summary: It includes a summary of the full information.\n",
            ", Approaches to Automatic summarization\n",
            "There are mainly two types of summarization:\n",
            "\n",
            "Extraction-based Summarization: The extractive approach involves picking up the most important phrases and lines from the documents., It then combines all the important lines to create the summary., So, in this case, every line and word of the summary actually belongs to the original document which is summarized.\n",
            "\n",
            ", Abstraction-based Summarization: The abstractive approach involves summarization based on deep learning., So, it uses new phrases and terms, different from the actual document, keeping the points the same, just like how we actually summarize., So, it is much harder than the extractive approach.\n",
            "\n",
            ", It has been observed that extractive summaries sometimes work better than the abstractive ones probably because extractive ones don’t require natural language generations and semantic representations.\n",
            "\n",
            ", Evaluation methods\n",
            "There are two types of evaluations:\n",
            "\n",
            "Human Evaluation\n",
            "Automatic Evaluation]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "sentence_scores = {}\n",
        "\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if str(sent) not in sentence_scores.keys():\n",
        "        sentence_scores[str(sent)] = word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "        sentence_scores[str(sent)] += word_frequencies[word.text.lower()]\n"
      ],
      "metadata": {
        "id": "rfRxySFQ8Ecu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTWLIBRj9i49",
        "outputId": "1980a087-a4b6-4644-bdf5-2d00847da03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\"Text summarization is commonly used by several websites and applications to create news feed and article summaries.': 2.0,\n",
              " 'It has become very essential for us due to our busy schedules.': 0.2727272727272727,\n",
              " 'We prefer short summaries with all the important points over reading a whole report and summarizing it ourselves.': 1.5454545454545452,\n",
              " 'So, several attempts had been made to automate the summarizing process.': 0.4545454545454546,\n",
              " 'In this article, we will talk about some of them and see how they work.\\n\\n': 1.1818181818181819,\n",
              " 'What is summarization?\\nSummarization is a technique to shorten long texts such that the summary has all the important points of the actual document.\\n\\n': 4.909090909090909,\n",
              " 'There are mainly four types of summaries:\\n\\nSingle Document Summary: Summary of a Single Document\\nMulti-Document Summary: Summary from multiple documents\\nQuery Focused Summary: Summary of a specific query\\nInformative Summary: It includes a summary of the full information.\\n': 12.727272727272732,\n",
              " 'Approaches to Automatic summarization\\nThere are mainly two types of summarization:\\n\\nExtraction-based Summarization: The extractive approach involves picking up the most important phrases and lines from the documents.': 5.818181818181817,\n",
              " 'It then combines all the important lines to create the summary.': 1.8181818181818183,\n",
              " 'So, in this case, every line and word of the summary actually belongs to the original document which is summarized.\\n\\n': 3.0,\n",
              " 'Abstraction-based Summarization: The abstractive approach involves summarization based on deep learning.': 2.909090909090909,\n",
              " 'So, it uses new phrases and terms, different from the actual document, keeping the points the same, just like how we actually summarize.': 1.9999999999999998,\n",
              " 'So, it is much harder than the extractive approach.\\n\\n': 1.4545454545454546,\n",
              " 'It has been observed that extractive summaries sometimes work better than the abstractive ones probably because extractive ones don’t require natural language generations and semantic representations.\\n\\n': 3.3636363636363633,\n",
              " 'Evaluation methods\\nThere are two types of evaluations:\\n\\nHuman Evaluation\\nAutomatic Evaluation': 2.2727272727272725}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "JwcrI3jP-nSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length = int(len(sentence_tokens)*0.3)\n",
        "select_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRJSiSFs-yyw",
        "outputId": "7e5dd9b3-76b4-4a25-b849-c7fb737d7b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = nlargest(select_length,sentence_scores,key=sentence_scores.get)\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsozfe_u--7c",
        "outputId": "7ab32b30-b637-4497-82f3-e5f46e8201ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There are mainly four types of summaries:\\n\\nSingle Document Summary: Summary of a Single Document\\nMulti-Document Summary: Summary from multiple documents\\nQuery Focused Summary: Summary of a specific query\\nInformative Summary: It includes a summary of the full information.\\n',\n",
              " 'Approaches to Automatic summarization\\nThere are mainly two types of summarization:\\n\\nExtraction-based Summarization: The extractive approach involves picking up the most important phrases and lines from the documents.',\n",
              " 'What is summarization?\\nSummarization is a technique to shorten long texts such that the summary has all the important points of the actual document.\\n\\n',\n",
              " 'It has been observed that extractive summaries sometimes work better than the abstractive ones probably because extractive ones don’t require natural language generations and semantic representations.\\n\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary =' '.join(summary)"
      ],
      "metadata": {
        "id": "7yIqwA9u_MbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZRDDvS-_XCP",
        "outputId": "8bf6afaf-54fd-4673-e5c7-48e5108ceec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are mainly four types of summaries:\\n\\nSingle Document Summary: Summary of a Single Document\\nMulti-Document Summary: Summary from multiple documents\\nQuery Focused Summary: Summary of a specific query\\nInformative Summary: It includes a summary of the full information.\\n Approaches to Automatic summarization\\nThere are mainly two types of summarization:\\n\\nExtraction-based Summarization: The extractive approach involves picking up the most important phrases and lines from the documents. What is summarization?\\nSummarization is a technique to shorten long texts such that the summary has all the important points of the actual document.\\n\\n It has been observed that extractive summaries sometimes work better than the abstractive ones probably because extractive ones don’t require natural language generations and semantic representations.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irsZodMq_a9-",
        "outputId": "2d0ca6e0-6efc-4f66-9b05-6237c8bd3094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1849"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5jh5XLF_k7k",
        "outputId": "def1b777-7413-4503-fb29-048288f69e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "843"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}